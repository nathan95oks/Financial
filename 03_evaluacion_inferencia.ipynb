{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1b99f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOTEBOOK 3: EVALUACIÓN E INFERENCIA\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"data_processed\"\n",
    "MODELS_DIR = \"models\"\n",
    "ID2LABEL = {0: \"Bajista\", 1: \"Alcista\", 2: \"Neutral\"}\n",
    "\n",
    "print(f\"Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. REDEFINICIÓN DE CLASES\n",
    "# -----------------------------------------------------------------------------\n",
    "# Necesario para que PyTorch pueda cargar la estructura del modelo guardado\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, rnn_output, mask):\n",
    "        scores = self.attn(rnn_output).squeeze(-1).masked_fill(mask == 0, -1e9)\n",
    "        attn_weights = torch.softmax(scores, dim=1)\n",
    "        return torch.sum(rnn_output * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "class RecurrentClassifier(nn.Module):\n",
    "    def __init__(self, model_type, vocab_size, embed_dim, hidden_dim, out_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        if model_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "        else:\n",
    "            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "        self.attention = AttentionPooling(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pad_idx = pad_idx\n",
    "        self.model_type = model_type\n",
    "    def forward(self, x):\n",
    "        mask = (x != self.pad_idx).float()\n",
    "        emb = self.embedding(x)\n",
    "        if self.model_type == 'lstm':\n",
    "            rnn_out, _ = self.rnn(emb)\n",
    "        else:\n",
    "            rnn_out, _ = self.rnn(emb)\n",
    "        context = self.attention(rnn_out, mask)\n",
    "        return self.fc(self.dropout(context))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. CARGA DEL MODELO Y EVALUACIÓN\n",
    "# -----------------------------------------------------------------------------\n",
    "def load_model(path):\n",
    "    print(f\"Cargando modelo desde: {path}\")\n",
    "    checkpoint = torch.load(path, map_location=DEVICE)\n",
    "    conf = checkpoint['config']\n",
    "    \n",
    "    model = RecurrentClassifier(\n",
    "        model_type=conf['model_type'],\n",
    "        vocab_size=conf['vocab_size'],\n",
    "        embed_dim=conf['embed_dim'],\n",
    "        hidden_dim=conf['hidden_dim'],\n",
    "        out_dim=3,\n",
    "        n_layers=conf['n_layers'],\n",
    "        dropout=conf['dropout'],\n",
    "        pad_idx=conf['pad_idx']\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model, checkpoint['vocab']\n",
    "\n",
    "# Cargar historial para graficar\n",
    "histories = pickle.load(open(f\"{MODELS_DIR}/history.pkl\", \"rb\"))\n",
    "\n",
    "# Graficar curvas de aprendizaje\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for m_name, h in histories.items():\n",
    "    plt.plot(h['train_loss'], label=f'{m_name.upper()} Train')\n",
    "    plt.plot(h['val_loss'], '--', label=f'{m_name.upper()} Val')\n",
    "plt.title(\"Pérdida (Loss)\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for m_name, h in histories.items():\n",
    "    plt.plot(h['train_acc'], label=f'{m_name.upper()} Train')\n",
    "    plt.plot(h['val_acc'], '--', label=f'{m_name.upper()} Val')\n",
    "plt.title(\"Precisión (Accuracy)\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. EVALUACIÓN EN TEST SET\n",
    "# -----------------------------------------------------------------------------\n",
    "# Elegimos el modelo LSTM para evaluar (puedes cambiar a 'gru_best_model.pth')\n",
    "model_path = f\"{MODELS_DIR}/lstm_best_model.pth\" \n",
    "model, vocab = load_model(model_path)\n",
    "\n",
    "test_df = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "\n",
    "def predict_batch(model, texts, vocab, max_len=40):\n",
    "    encoded_list = []\n",
    "    for t in texts:\n",
    "        tokens = str(t).lower().split()\n",
    "        ids = [vocab.get(tok, vocab[\"<UNK>\"]) for tok in tokens]\n",
    "        if len(ids) < max_len:\n",
    "            ids = ids + [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:max_len]\n",
    "        encoded_list.append(ids)\n",
    "    \n",
    "    x = torch.tensor(encoded_list, dtype=torch.long).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    return preds\n",
    "\n",
    "print(\"\\nRealizando predicciones en Test Set...\")\n",
    "y_pred = predict_batch(model, test_df[\"text\"].values, vocab)\n",
    "y_true = test_df[\"label\"].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" REPORTE DE CLASIFICACIÓN (TEST SET)\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Bajista\", \"Alcista\", \"Neutral\"]))\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Bajista\", \"Alcista\", \"Neutral\"], \n",
    "            yticklabels=[\"Bajista\", \"Alcista\", \"Neutral\"])\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. INFERENCIA INTERACTIVA\n",
    "# -----------------------------------------------------------------------------\n",
    "def analizar_frase(texto):\n",
    "    model.eval()\n",
    "    pred_idx = predict_batch(model, [texto], vocab)[0]\n",
    "    \n",
    "    # Obtener probabilidades para mostrar confianza (opcional)\n",
    "    # Requeriría modificar predict_batch para devolver softmax, pero esto basta\n",
    "    etiqueta = ID2LABEL[pred_idx]\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Texto: '{texto}'\")\n",
    "    print(f\"Predicción: {etiqueta} ({pred_idx})\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n=== PRUEBAS EN VIVO ===\")\n",
    "analizar_frase(\"The market is crashing hard, everything is red!\")\n",
    "analizar_frase(\"Apple reported amazing earnings, stock is flying to the moon\")\n",
    "analizar_frase(\"The fed will announce interest rates tomorrow, market is waiting\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
