{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484ab480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Cargando datos procesados...\n",
      "Dataloaders listos.\n",
      "Pesos por clase: [0.50463279 0.37781801 0.11754921]\n",
      "\n",
      "========================================\n",
      " Entrenando: LSTM_BASE (Bi=False, Attn=False)\n",
      "========================================\n",
      "Epoch 1/12 | Train Loss: 1.0856 Acc: 0.4165 | Val Loss: 1.0715 Acc: 0.5958\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_base_best_model.pth\n",
      "Epoch 2/12 | Train Loss: 0.9693 Acc: 0.6325 | Val Loss: 0.9731 Acc: 0.6580\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_base_best_model.pth\n",
      "Epoch 3/12 | Train Loss: 0.8476 Acc: 0.6840 | Val Loss: 1.0869 Acc: 0.7091\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_base_best_model.pth\n",
      "Epoch 4/12 | Train Loss: 0.7135 Acc: 0.7658 | Val Loss: 0.9305 Acc: 0.6846\n",
      "Epoch 5/12 | Train Loss: 0.6143 Acc: 0.8064 | Val Loss: 0.8833 Acc: 0.6972\n",
      "Epoch 6/12 | Train Loss: 0.5251 Acc: 0.8396 | Val Loss: 1.0344 Acc: 0.7084\n",
      "Epoch 7/12 | Train Loss: 0.4357 Acc: 0.8691 | Val Loss: 1.0388 Acc: 0.7203\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_base_best_model.pth\n",
      "Epoch 8/12 | Train Loss: 0.3864 Acc: 0.8888 | Val Loss: 0.9945 Acc: 0.6923\n",
      "Epoch 9/12 | Train Loss: 0.3478 Acc: 0.8990 | Val Loss: 1.0386 Acc: 0.7077\n",
      "Epoch 10/12 | Train Loss: 0.3046 Acc: 0.9118 | Val Loss: 1.1379 Acc: 0.7322\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_base_best_model.pth\n",
      "Epoch 11/12 | Train Loss: 0.2830 Acc: 0.9184 | Val Loss: 1.1367 Acc: 0.7133\n",
      "Epoch 12/12 | Train Loss: 0.2611 Acc: 0.9263 | Val Loss: 1.1883 Acc: 0.7210\n",
      "\n",
      "========================================\n",
      " Entrenando: LSTM_ATTN (Bi=False, Attn=True)\n",
      "========================================\n",
      "Epoch 1/12 | Train Loss: 1.0291 Acc: 0.5386 | Val Loss: 0.9449 Acc: 0.6580\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 2/12 | Train Loss: 0.8350 Acc: 0.6833 | Val Loss: 0.8804 Acc: 0.6944\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 3/12 | Train Loss: 0.6557 Acc: 0.7554 | Val Loss: 0.8663 Acc: 0.6979\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 4/12 | Train Loss: 0.4651 Acc: 0.8330 | Val Loss: 0.9339 Acc: 0.6951\n",
      "Epoch 5/12 | Train Loss: 0.3678 Acc: 0.8683 | Val Loss: 0.9836 Acc: 0.7406\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 6/12 | Train Loss: 0.2917 Acc: 0.8966 | Val Loss: 1.0736 Acc: 0.7007\n",
      "Epoch 7/12 | Train Loss: 0.2125 Acc: 0.9275 | Val Loss: 1.1619 Acc: 0.7497\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 8/12 | Train Loss: 0.1710 Acc: 0.9420 | Val Loss: 1.2239 Acc: 0.7517\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 9/12 | Train Loss: 0.1377 Acc: 0.9552 | Val Loss: 1.4046 Acc: 0.7587\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_attn_best_model.pth\n",
      "Epoch 10/12 | Train Loss: 0.1035 Acc: 0.9655 | Val Loss: 1.5283 Acc: 0.7580\n",
      "Epoch 11/12 | Train Loss: 0.0938 Acc: 0.9721 | Val Loss: 1.5487 Acc: 0.7566\n",
      "Epoch 12/12 | Train Loss: 0.0832 Acc: 0.9744 | Val Loss: 1.6376 Acc: 0.7462\n",
      "\n",
      "========================================\n",
      " Entrenando: GRU_BASE (Bi=False, Attn=False)\n",
      "========================================\n",
      "Epoch 1/12 | Train Loss: 1.0900 Acc: 0.4315 | Val Loss: 1.0622 Acc: 0.6692\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_base_best_model.pth\n",
      "Epoch 2/12 | Train Loss: 0.9708 Acc: 0.6205 | Val Loss: 0.9529 Acc: 0.6392\n",
      "Epoch 3/12 | Train Loss: 0.8510 Acc: 0.6807 | Val Loss: 0.8843 Acc: 0.6042\n",
      "Epoch 4/12 | Train Loss: 0.6660 Acc: 0.7693 | Val Loss: 0.9334 Acc: 0.7035\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_base_best_model.pth\n",
      "Epoch 5/12 | Train Loss: 0.5464 Acc: 0.8235 | Val Loss: 0.8817 Acc: 0.6972\n",
      "Epoch 6/12 | Train Loss: 0.4375 Acc: 0.8598 | Val Loss: 0.9669 Acc: 0.7287\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_base_best_model.pth\n",
      "Epoch 7/12 | Train Loss: 0.3537 Acc: 0.8881 | Val Loss: 1.0060 Acc: 0.7420\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_base_best_model.pth\n",
      "Epoch 8/12 | Train Loss: 0.3033 Acc: 0.9050 | Val Loss: 1.0145 Acc: 0.7280\n",
      "Epoch 9/12 | Train Loss: 0.2590 Acc: 0.9170 | Val Loss: 1.1508 Acc: 0.7420\n",
      "Epoch 10/12 | Train Loss: 0.2161 Acc: 0.9329 | Val Loss: 1.1653 Acc: 0.7531\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_base_best_model.pth\n",
      "Epoch 11/12 | Train Loss: 0.2024 Acc: 0.9387 | Val Loss: 1.1921 Acc: 0.7503\n",
      "Epoch 12/12 | Train Loss: 0.1810 Acc: 0.9413 | Val Loss: 1.2583 Acc: 0.7545\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_base_best_model.pth\n",
      "\n",
      "========================================\n",
      " Entrenando: GRU_ATTN (Bi=False, Attn=True)\n",
      "========================================\n",
      "Epoch 1/12 | Train Loss: 1.0077 Acc: 0.5613 | Val Loss: 0.9257 Acc: 0.6692\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_attn_best_model.pth\n",
      "Epoch 2/12 | Train Loss: 0.8120 Acc: 0.6831 | Val Loss: 0.8652 Acc: 0.7070\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_attn_best_model.pth\n",
      "Epoch 3/12 | Train Loss: 0.6417 Acc: 0.7542 | Val Loss: 0.8227 Acc: 0.6972\n",
      "Epoch 4/12 | Train Loss: 0.4571 Acc: 0.8270 | Val Loss: 0.8744 Acc: 0.7105\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_attn_best_model.pth\n",
      "Epoch 5/12 | Train Loss: 0.3702 Acc: 0.8562 | Val Loss: 0.9214 Acc: 0.7503\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_attn_best_model.pth\n",
      "Epoch 6/12 | Train Loss: 0.2926 Acc: 0.8903 | Val Loss: 1.0098 Acc: 0.7594\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/gru_attn_best_model.pth\n",
      "Epoch 7/12 | Train Loss: 0.2180 Acc: 0.9184 | Val Loss: 1.0987 Acc: 0.7441\n",
      "Epoch 8/12 | Train Loss: 0.1821 Acc: 0.9335 | Val Loss: 1.1776 Acc: 0.7517\n",
      "Epoch 9/12 | Train Loss: 0.1537 Acc: 0.9425 | Val Loss: 1.2883 Acc: 0.7552\n",
      "Epoch 10/12 | Train Loss: 0.1199 Acc: 0.9591 | Val Loss: 1.3474 Acc: 0.7483\n",
      "Epoch 11/12 | Train Loss: 0.1042 Acc: 0.9637 | Val Loss: 1.4049 Acc: 0.7538\n",
      "Epoch 12/12 | Train Loss: 0.0947 Acc: 0.9670 | Val Loss: 1.4554 Acc: 0.7531\n",
      "\n",
      "========================================\n",
      " Entrenando: LSTM_BI (Bi=True, Attn=False)\n",
      "========================================\n",
      "Epoch 1/12 | Train Loss: 1.0121 Acc: 0.5751 | Val Loss: 0.9213 Acc: 0.6804\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 2/12 | Train Loss: 0.7955 Acc: 0.7110 | Val Loss: 0.8162 Acc: 0.7056\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 3/12 | Train Loss: 0.6025 Acc: 0.7850 | Val Loss: 0.8075 Acc: 0.7196\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 4/12 | Train Loss: 0.4197 Acc: 0.8526 | Val Loss: 0.8598 Acc: 0.7336\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 5/12 | Train Loss: 0.3233 Acc: 0.8893 | Val Loss: 0.9506 Acc: 0.7392\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 6/12 | Train Loss: 0.2410 Acc: 0.9140 | Val Loss: 1.1085 Acc: 0.7622\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 7/12 | Train Loss: 0.1643 Acc: 0.9426 | Val Loss: 1.3152 Acc: 0.7643\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_best_model.pth\n",
      "Epoch 8/12 | Train Loss: 0.1319 Acc: 0.9521 | Val Loss: 1.3038 Acc: 0.7552\n",
      "Epoch 9/12 | Train Loss: 0.1024 Acc: 0.9628 | Val Loss: 1.5518 Acc: 0.7615\n",
      "Epoch 10/12 | Train Loss: 0.0742 Acc: 0.9745 | Val Loss: 1.5347 Acc: 0.7524\n",
      "Epoch 11/12 | Train Loss: 0.0616 Acc: 0.9777 | Val Loss: 1.5798 Acc: 0.7497\n",
      "Epoch 12/12 | Train Loss: 0.0512 Acc: 0.9819 | Val Loss: 1.8858 Acc: 0.7643\n",
      "\n",
      "========================================\n",
      " Entrenando: LSTM_BI_ATTN (Bi=True, Attn=True)\n",
      "========================================\n",
      "Epoch 1/12 | Train Loss: 0.9835 Acc: 0.5924 | Val Loss: 0.9064 Acc: 0.6895\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 2/12 | Train Loss: 0.7544 Acc: 0.7050 | Val Loss: 0.8134 Acc: 0.7035\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 3/12 | Train Loss: 0.5528 Acc: 0.7892 | Val Loss: 0.8178 Acc: 0.7105\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 4/12 | Train Loss: 0.3660 Acc: 0.8608 | Val Loss: 0.9047 Acc: 0.7469\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 5/12 | Train Loss: 0.2511 Acc: 0.9025 | Val Loss: 1.0080 Acc: 0.7455\n",
      "Epoch 6/12 | Train Loss: 0.1729 Acc: 0.9342 | Val Loss: 1.1297 Acc: 0.7517\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 7/12 | Train Loss: 0.1084 Acc: 0.9645 | Val Loss: 1.4752 Acc: 0.7678\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 8/12 | Train Loss: 0.0779 Acc: 0.9726 | Val Loss: 1.6296 Acc: 0.7566\n",
      "Epoch 9/12 | Train Loss: 0.0583 Acc: 0.9804 | Val Loss: 1.6688 Acc: 0.7706\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 10/12 | Train Loss: 0.0392 Acc: 0.9853 | Val Loss: 1.7993 Acc: 0.7664\n",
      "Epoch 11/12 | Train Loss: 0.0294 Acc: 0.9894 | Val Loss: 2.0291 Acc: 0.7741\n",
      " --> Nuevo r\u00e9cord! Modelo guardado en models/lstm_bi_attn_best_model.pth\n",
      "Epoch 12/12 | Train Loss: 0.0237 Acc: 0.9924 | Val Loss: 2.0418 Acc: 0.7720\n",
      "\n",
      "\u00a1Entrenamiento finalizado para LSTM, GRU y BiLSTM!\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 6. ENTRENAMIENTO DE MODELOS (LSTM, GRU, BiLSTM)\n",
    "# -----------------------------------------------------------------------------\n",
    "histories = {}\n",
    "\n",
    "configs = [\n",
    "    {'name': 'lstm_base', 'type': 'lstm', 'bi': False, 'attn': False},\n",
    "    {'name': 'lstm_attn', 'type': 'lstm', 'bi': False, 'attn': True},\n",
    "    {'name': 'gru_base',  'type': 'gru',  'bi': False, 'attn': False},\n",
    "    {'name': 'gru_attn',  'type': 'gru',  'bi': False, 'attn': True},\n",
    "    {'name': 'lstm_bi',   'type': 'lstm', 'bi': True,  'attn': False},\n",
    "    {'name': 'lstm_bi_attn','type':'lstm','bi': True,  'attn': True}\n",
    "]\n",
    "\n",
    "for conf in configs:\n",
    "    m_name = conf['name']\n",
    "    m_type = conf['type']\n",
    "    bi = conf['bi']\n",
    "    attn = conf['attn']\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\" Entrenando: {m_name.upper()} (Bi={bi}, Attn={attn})\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    model = RecurrentClassifier(\n",
    "        model_type=m_type,\n",
    "        vocab_size=len(vocab),\n",
    "        embed_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        out_dim=3,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=vocab[\"<PAD>\"],\n",
    "        bidirectional=bi,\n",
    "        use_attention=attn\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'total_time': 0}\n",
    "    \n",
    "    start_time = time.time() # Start timer\n",
    "    \n",
    "    for ep in range(EPOCHS):\n",
    "        tl, ta = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        vl, va = evaluate(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(tl)\n",
    "        history['val_loss'].append(vl)\n",
    "        history['train_acc'].append(ta)\n",
    "        history['val_acc'].append(va)\n",
    "        \n",
    "        print(f\"Epoch {ep+1}/{EPOCHS} | Train Loss: {tl:.4f} Acc: {ta:.4f} | Val Loss: {vl:.4f} Acc: {va:.4f}\")\n",
    "        \n",
    "        if va > best_acc:\n",
    "            best_acc = va\n",
    "            state = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'config': {\n",
    "                    'model_type': m_type,\n",
    "                    'vocab_size': len(vocab),\n",
    "                    'embed_dim': EMBEDDING_DIM, \n",
    "                    'hidden_dim': HIDDEN_DIM,\n",
    "                    'n_layers': N_LAYERS,\n",
    "                    'dropout': DROPOUT,\n",
    "                    'pad_idx': vocab[\"<PAD>\"],\n",
    "                    'bidirectional': bi,\n",
    "                    'use_attention': attn\n",
    "                },\n",
    "                'vocab': vocab\n",
    "            }\n",
    "            save_path = f\"{MODELS_DIR}/{m_name}_best_model.pth\"\n",
    "            torch.save(state, save_path)\n",
    "            print(f\" --> Nuevo r\u00e9cord! Modelo guardado en {save_path}\")\n",
    "            \n",
    "    end_time = time.time() # End timer\n",
    "    total_time = end_time - start_time\n",
    "    history['total_time'] = total_time\n",
    "    print(f\"Tiempo total de entrenamiento: {total_time:.2f} segundos\")\n",
    "    \n",
    "    histories[m_name] = history\n",
    "\n",
    "print(\"\\n\u00a1Entrenamiento finalizado para LSTM, GRU y BiLSTM!\")\n",
    "\n",
    "# Guardar historial completo\n",
    "with open(f\"{MODELS_DIR}/histories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(histories, f)\n",
    "print(f\"Historial guardado en {MODELS_DIR}/histories.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mx110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}